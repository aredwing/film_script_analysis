{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Film Script Analyzer\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "## IBM Watson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"IBM Watson is a technology platform that uses natural language processing and machine learning to reveal insights from large amounts of unstructured data\"\n",
    "\n",
    "Watson's interfase needs a [registered account](https://www.ibm.com/account/us-en/signup/register.html?a=MTBmNDg2NDktNDI2MC00&ctx=C001&trial=yes&catalogName=Master&quantity=1&partNumber=WA2PROTRIAL&source=mrsaas-trial-ibmid&pkg=ov49121&S_TACT=000000WB&S_OFF_CD=10000752&siteID=WA&watsonanalytics=true), which assigns a needed username / password.\n",
    "\n",
    "The process is as follows:\n",
    "- Authenticate with username/password\n",
    "- Submit text to be analized\n",
    "- Receive analysis of text, 30 features that describe the data.\n",
    "\n",
    "Such features are:\n",
    "![features](pi_viz.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign variables with username / password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iusername = 'ABCDE'\n",
    "ipassword = '12345'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function **'insight'** to submit the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from watson_developer_cloud import PersonalityInsightsV2 as PerIns\n",
    "\n",
    "def insight(text,user,password):\n",
    "    connect = PerIns(username=user,password=password)\n",
    "    return connect.profile(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send text to analyze, store it in the insights dictionary, then save to disk as a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insights = {}\n",
    "\n",
    "for row in df.index:\n",
    "    if row not in insights.keys():\n",
    "        temp    = open('scripts/'+row,'r').read()\n",
    "        insights.update({row:insight(temp,iusername,ipassword)})\n",
    "        \n",
    "with open('data/insights.json','w') as f:\n",
    "    json.dump(insights,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define **'flatten'** function to extract data from the insights dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(orig):\n",
    "    data = {}\n",
    "    for c in orig['tree']['children']:\n",
    "        if 'children' in c:\n",
    "            for c2 in c['children']:\n",
    "                if 'children' in c2:\n",
    "                    for c3 in c2['children']:\n",
    "                        if 'children' in c3:\n",
    "                            for c4 in c3['children']:\n",
    "                                if (c4['category'] == 'personality'):\n",
    "                                    data[c4['id']] = c4['percentage']\n",
    "                                    if 'children' not in c3:\n",
    "                                        if (c3['category'] == 'personality'):\n",
    "                                                data[c3['id']] = c3['percentage']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through all the insights and flatten them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finsights = {}\n",
    "for key in insights.keys():\n",
    "    finsights.update({key:flatten(insights[key])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert it to dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = finsights.values()[0].keys()\n",
    "index   = df.index\n",
    "df3     = pd.DataFrame(index=index,columns=columns)\n",
    "\n",
    "for row in index:\n",
    "    for feature in columns:\n",
    "        df3[feature].ix[row] = finsights[row][feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the original **17,271** scrapped files after filtering and cleaning **12,713** remain.\n",
    "\n",
    "Concatenate the new dataset with the previous one and save it to disk.\n",
    "\n",
    "This is the core data that will be used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = pd.concat([df3,df],axis=1)\n",
    "df0.to_csv('data/df0.csv',encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
